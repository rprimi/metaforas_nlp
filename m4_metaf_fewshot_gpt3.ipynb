{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9cX_0AoJKwHv"},"outputs":[],"source":["###########\n","# IMPORTS #\n","###########\n","\n","!pip install openai\n","#!pip install transformers\n","#!pip install datasets\n","#!pip install torchinfo\n","\n","from google.colab import drive\n","import openai\n","import os\n","import pandas as pd\n","import random\n","import re\n","import torch\n","\n","#from transformers import AutoTokenizer  # Or BertTokenizer\n","#from transformers import AutoModelForPreTraining  # Or BertForPreTraining for loading pretraining heads\n","#from transformers import AutoModel  # or BertModel, for BERT without pretraining heads\n","#from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","#from transformers import pipeline\n","#import xml.etree.ElementTree as ET\n","\n","# from torchinfo import summary\n","import numpy as np\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","#from urllib.parse import urlparse"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20809,"status":"ok","timestamp":1669833513932,"user":{"displayName":"Ricardo Primi","userId":"05260074563804687088"},"user_tz":180},"id":"v2e2i6vkLjsv","outputId":"f8253462-1612-40fb-a4a6-9ab731d2e58d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":[" from google.colab import drive\n"," drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYkJFXyP6v9X"},"outputs":[],"source":["#######\n","# GPU #\n","#######\n","\n","# ! pip install accelerate\n","# from accelerate import Accelerator\n","\n","# # use_fp16 = True\n","# use_fp16 = False\n","\n","# if torch.cuda.is_available(): \n","#     dev = \"cuda:0\"\n","#     accelerator = Accelerator(mixed_precision='fp16') if use_fp16 else Accelerator(mixed_precision='no')\n","# else:\n","#     dev = \"cpu\"\n","#     accelerator = Accelerator(mixed_precision='no')\n","\n","# device = accelerator.device\n","# print('Using {}'.format(device))"]},{"cell_type":"code","source":["bd_test = pd.read_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_db.csv\") \n","\n","bd_test.info\n","bd_test\n","\n","bd_test.test_prompt[1]"],"metadata":{"id":"5MJb6C6g0ijJ","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1669833515319,"user_tz":180,"elapsed":1390,"user":{"displayName":"Ricardo Primi","userId":"05260074563804687088"}},"outputId":"8556aef5-2ab0-4912-bdf8-615fa80d8718"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Abaixo há uma lista de analogias. Em uma escala de 0-3 julgue quão criativas e originais são as analogias sendo 0 é \"nada criativo\" e 3 \"muito criativo\". \\n\\nANALOGIAS \\n1. Bola : amor : Jogadores. correm atras dela no minimo 90 minutos por dia e sem parar \\n2. Bola : martelo : Jogadores. pq é o instrumento de trabalho dos carpinteiros \\n3. Trovao : plim plim : Chuva. o trovão anúncia a chuva assim como o plim plim anúncia uma programação \\n4. Peixes : tribos : Mar. cada um com seu cardume curte uma onda diferente \\n5. Planetas : partes : Sol. porque os planeta faz parte do so \\n6. Buzina : instrumento musical : Carro. pq ambos tocam \\n7. Buzina : rugido : Carro. NA \\n8. Estrelas : raios : Noite. pq ambos vêm do céu e têm uma luz incandescente \\n9. Buzina : choro : Carro. por que quando quer reclamar de algo no trânsito buzina e a criança chora \\n10. Cabide : pessoa : Roupa. porque o cabide segura as roupas e a pessoa também segura a roupa como um cabide \\n11. Onibus : veias : Cidade. pq levam e trazem pessoas, como se estas fossem sangue, células…. \\n12. Buzina : grito : Carro. pq é acionada em momentos de susto ou atenção \\n13. Espuma : suor : Sabao. espuma é a transpiração do sabão \\n14. Grama : cabelo : Terra. pq ambas nascem à superficie \\n15. Estrelas : vagalumes : Noite. são os vagalumes do universo \\n16. Buzina : Grito : Carro. Para poder evidenciá-lo. \\n18. Grama : cobertura : Terra. pq a grama está na parte superior da terra\\n\\nAVALIAÇÕES \\n1. 0 \\n2. 1 \\n3. 2 \\n4. 3 \\n5. 0 \\n6. 3 \\n7. 0 \\n8. 1 \\n9. 3 \\n10. 1 \\n11. 2 \\n12. 1 \\n13. 2 \\n14. 2 \\n15. 3 \\n16. 0 \\n18'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import openai\n","import os\n","import pandas as pd\n","import random\n","\n","\n","\n","def few_shot(data, inic, fim):\n","    model_answers = []\n","  \n","    for i in range(inic, fim):\n","        response = openai.Completion.create(\n","            model=\"text-davinci-003\",\n","            prompt =data.test_prompt[i],\n","            temperature=0.7,\n","            max_tokens=275,\n","            top_p=1,\n","            frequency_penalty=0,\n","            presence_penalty=0\n","            )\n","        model_answers.append(response)\n","        \n","    return model_answers\n","\n","\n","test_eval_gpt3_2 = few_shot(data = bd_test2, inic=21, fim=101)\n"],"metadata":{"id":"QxpnRvJs1Gu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bd_test1 = bd_test.iloc[0:20]\n","bd_test2 = bd_test.iloc[21:102]\n","bd_test3 = bd_test.iloc[102:1000]\n","bd_test4 = bd_test.iloc[713:1200]\n","bd_test5 = bd_test.iloc[1200:]\n","\n","len(bd_test5)\n","\n","\n","pd.DataFrame(bd_test1 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/bd_test1.csv\")\n","pd.DataFrame(bd_test2 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/bd_test2.csv\")\n","pd.DataFrame(bd_test3 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/bd_test3.csv\")\n","pd.DataFrame(bd_test4 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/bd_test4.csv\")\n","pd.DataFrame(bd_test5 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/bd_test5.csv\")\n","len(bd_test4)\n","\n","\n","len(bd_test)\n","\n","bd_test5.test_prompt[2571]"],"metadata":{"id":"wCjBL7gn2lan","executionInfo":{"status":"ok","timestamp":1669837590154,"user_tz":180,"elapsed":267,"user":{"displayName":"Ricardo Primi","userId":"05260074563804687088"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","\n","model_answers = []\n","inic = 1200\n","fim = 2571\n","data = bd_test5\n","\n","for i in range(inic, fim):\n","    \n","    response = openai.Completion.create(\n","    model=\"text-davinci-003\",\n","    prompt =data.test_prompt[i],\n","    temperature=0.7,\n","    max_tokens=275,\n","    top_p=1,\n","    frequency_penalty=0,\n","    presence_penalty=0,\n","    logprobs=5,\n","    echo=True\n","    )\n","    print('Ideia: ', i)\n","    model_answers.append(response)\n"," \n","\n","#len(model_answers)\n","#model_answers[0]"],"metadata":{"id":"6LhUX5XU5cf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(model_answers) \n","test_eval_gpt3_7 = model_answers\n","\n","len(test_eval_gpt3_3 )\n","\n","pd.DataFrame(test_eval_gpt3_1 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_1.csv\")\n","pd.DataFrame(test_eval_gpt3_2 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_2.csv\")\n","pd.DataFrame(test_eval_gpt3_3 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_3.csv\")\n","pd.DataFrame(test_eval_gpt3_4 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_4.csv\")\n","pd.DataFrame(test_eval_gpt3_5 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_5.csv\")\n","pd.DataFrame(test_eval_gpt3_6 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_6.csv\")\n","pd.DataFrame(test_eval_gpt3_7 ).to_csv(\"/content/drive/MyDrive/unicamp - IA024 /projeto_metaf/test_eval_gpt3_7.csv\")\n","\n","test_eval_gpt3_4[0]"],"metadata":{"id":"2CPH5W164G6U","executionInfo":{"status":"ok","timestamp":1669837557579,"user_tz":180,"elapsed":20638,"user":{"displayName":"Ricardo Primi","userId":"05260074563804687088"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["for i in range(20):\n","  print(test_eval_gpt3_1[i])"],"metadata":{"id":"ewUvoVqH3xPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAnne6WrMma7"},"outputs":[],"source":["######################\n","# OPENAI MODEL SETUP #\n","######################\n","\n","openai.api_key = \"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\"\n","\n","# TODO: echo = True e logprobs = True\n","\n","def prompt_openai(text_prompt):\n","\n","    response = openai.Completion.create(\n","        model=\"text-davinci-002\",\n","        prompt=text_prompt,\n","        temperature=0,\n","        max_tokens=512,# TODO: max_length tokenizer\n","        top_p=1,\n","        frequency_penalty=0,\n","        presence_penalty=0\n","    )\n","\n","    # alternative = response['choices'][0]['text']\n","    alternative = re.sub('[^a-zA-Z]+', '', response['choices'][0]['text'])[0]\n","\n","    return response, alternative"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHnIM5PuRlGa"},"outputs":[],"source":["def get_label(d):\n","  return int(d['label'].split('_')[1])\n","\n","test_pred2 = [get_label(d) for d in test_pred]\n","\n","print(\"acc:\", accuracy_score(raw_dataset['test']['label'], test_pred2))\n","print(\"f1:\", f1_score(raw_dataset['test']['label'], test_pred2, average='micro'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8OM9W1vzSTxW"},"outputs":[],"source":["# Scikit-Learn is transitioning to V1 but it's not available on Colab\n","# The changes modify how confusion matrices are plotted\n","def plot_cm(cm):\n","  classes = ['0', '1']\n","  df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n","  ax = sn.heatmap(df_cm, annot=True, fmt='g')\n","  ax.set_xlabel(\"Predicted\")\n","  ax.set_ylabel(\"Target\")\n","\n","cm = confusion_matrix(tokenized_datasets['test']['label'], test_pred2, normalize='true')\n","plot_cm(cm)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1pybsNzaVmjEr7NcEfWSI8SHa5p8JEiZJ","timestamp":1669562039613},{"file_id":"1eAwHpvh9P-W3uRlX79VjirvUuaF8vBx0","timestamp":1669561976138}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}